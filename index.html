<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
    <meta property="og:title" content="MathArena.ai"/>
  <meta property="og:description" content="MathArena: Live Leaderboards for Math Competitions and Olympiads"/>
  <meta property="description" content="MathArena: Live Leaderboards for Math Competitions and Olympiads"/>

  <meta property="og:url" content="https://matharena.ai/"/>
    <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
  <meta name="keywords" content="Math, LLM, Olympiads, Competitions, Leaderboards, AI, Machine Learning, MathArena, MathArena.ai"/>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">

  <meta name="viewport" content="width=device-width, initial-scale=1">



  <title>MathArena</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/2.0.7/css/dataTables.dataTables.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/material-components-web/14.0.0/material-components-web.min.js">
  <link rel="stylesheet" href="static/css/index.css">
  
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.1.0/es5/tex-mml-chtml.js">
</script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script type="text/javascript" charset="utf8" src="https://cdn.datatables.net/2.0.7/js/dataTables.min.js"></script>
  <script src="static/js/index.js"></script>
  
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MathArena.ai: LLMs on Recent Math Competitions and Olympiads</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">SRI Lab @ ETH Zurich</span>
            </div>
          </div>
        </div>
      </div>
</div>
      
      
    </div>
  </div>
</section>

<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-justified">
          <div class="table-info-box">
            <b>Model scores on AIME I 2025</b>
        </div>
          <table id="myTopTable" class="display" style="width:100%">
            <thead>
                <tr>
                    <th rowspan="2" class="model-name">Model Name</th>
                    <th colspan="17" class="competition-name">AIME I 2025</th>
                    <!-- <th colspan="1">o3-mini</th>
                    <th colspan="1">o1</th>
                    <th colspan="1">o1-mini</th>
                    <th colspan="1">R1</th>
                    <th colspan="1">Gemini-Flash-Thinking</th> -->
                    <!-- <th>GSM8k</th>
                    <th>Hellaswag</th>
                    <th rowspan="2">MMLU</th> -->
                </tr>
                <tr>
                  <th colspan="1">1</th>
                  <th colspan="1">2</th>
                  <th colspan="1">3</th>
                  <th colspan="1">4</th>
                  <th colspan="1">5</th>
                  <th colspan="1">6</th>
                  <th colspan="1">7</th>
                  <th colspan="1">8</th>
                  <th colspan="1">9</th>
                  <th colspan="1">10</th>
                  <th colspan="1">11</th>
                  <th colspan="1">12</th>
                  <th colspan="1">13</th>
                  <th colspan="1">14</th>
                  <th colspan="1">15</th>
                  <th colspan="1">Acc</th>
                  <th colspan="1">Cost</th>
              </tr>
            </thead>
            <tbody>
            </tbody>
        </table>
        </div>
      </div>
      </div>
      </div>
</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">What is MathArena.ai?</h2>
        <div class="content has-text-justified">
          <!-- <div class="caption">
            We pit LLMs against each other and humans on recent math competitions and olympiads, providing the possibility for uncontaminated model evaluation. 
            We hope that this will lead to better understanding of the capabilities and limitations of LLMs on math tasks.
          </div> -->
          <p>
            MathArena is a platform for evaluating LLMs on math competitions and olympiads.
            Our goal is the accurate evaluation of LLMs on math tasks that are not seen during training. 
            For this reason, we only evaluate models on competitions that were released after model release. We do not retroactively evaluate models on already existing competitions.
            Furthermore, by performing standardized evaluation, we ensure model scores are actually comparable and are not dependent on the specific evaluation setup of the model provider.
            <br>
            To show the model performances, we provide a leaderboard for each competition showing the scores of different models on each problem.
            Additionally, we will include a main table that includes model performance on all competitions.
            To evaluate performance, we run each model several times on each problem, computing the average score and the cost of the model across all runs.
            In the tables, green problems are solved >66% of the time, yellow problems are solved 33-66% of the time, and red problems are solved less than 33% of the time.
            <br>
            For further information, we refer to our <a href="https://github.com/eth-sri/matharena">GitHub repository</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <br>
          <img class="logos" src="static/images/footer.svg" alt="ETH & SRI Logo">
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Cloudflare Web Analytics -->
<!-- <script defer src='https://static.cloudflareinsights.com/beacon.min.js' 
  data-cf-beacon='{"token": "7bd3fd9fa4364e41be6356f27688372d"}'></script> -->
<!-- End Cloudflare Web Analytics -->
<!-- TODO -->

  </body>
  </html>
